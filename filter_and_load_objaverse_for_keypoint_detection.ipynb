{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Downloading meshes from objaverse for categories like planes or cars and generating point clouds from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import signal\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "# , point_cloud_generation_from_mesh\n",
    "from process_msh_ply import ply2projections\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data based on other annotations like names \n",
    "\n",
    "Let's load the different names annotated in the dataset and write them to a file so we can look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import objaverse\n",
    "import multiprocessing\n",
    "processes = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = objaverse.load_uids()\n",
    "annotations = objaverse.load_annotations()\n",
    "annotations[uids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvis_annotations = objaverse.load_lvis_annotations()\n",
    "# get all annotation names from the dictionary\n",
    "annotation_names = list(lvis_annotations.keys())\n",
    "\n",
    "# save all annotation names to a csv file\n",
    "import csv\n",
    "with open(\"annotation_names.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(annotation_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select uids based on the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all uids for airplane, jet_plane, fighter_jet\n",
    "airplane_uids = lvis_annotations[\"airplane\"] + lvis_annotations[\"jet_plane\"] + lvis_annotations[\"fighter_jet\"]\n",
    "print(\"Number of airplane:\", len(airplane_uids))\n",
    "\n",
    "# get all uids for bicycle\n",
    "bicycle_uids = lvis_annotations[\"bicycle\"]\n",
    "print(\"Number of bicycle:\", len(bicycle_uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load david_holiday_cars.csv and get all the uids\n",
    "df = pd.read_csv(\"david_holiday_cars.csv\")\n",
    "car_uids = df[\"uid\"].tolist()\n",
    "print(\"Number of cars:\", len(car_uids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: Let's load the shapes with plane, bicycle or car associated with them.\n",
    "\n",
    "> Note: You don't neccessarily need the annotations but you could use them to filter the data a little further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all car annotations\n",
    "filtered_annotations = objaverse.load_annotations(uids=bicycle_uids)\n",
    "\n",
    "# filter out the car annotations that have a face count smaller than 100 and save the new uid list\n",
    "filtered_annotations = {uid: annotation for uid, annotation in filtered_annotations.items(\n",
    ") if annotation[\"faceCount\"] >= 100}\n",
    "filtered_uids = list(filtered_annotations.keys())\n",
    "len(filtered_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the plane objects\n",
    "downloaded_objects = objaverse.load_objects(\n",
    "    uids=filtered_uids, download_processes=processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives a dictionary of objects with uid as key and the path to the object as value\n",
    "print(len(downloaded_objects))\n",
    "downloaded_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plane_objects to a csv file using pandas\n",
    "df = pd.DataFrame.from_dict(downloaded_objects, orient=\"index\")\n",
    "df.to_csv(\"bicycle_objects.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point cloud generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cloud_generation_from_mesh(mesh_path, pc_full_path=None):\n",
    "    # Load the mesh from a .glb file\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "\n",
    "    # Sample points on the mesh surface\n",
    "    point_cloud = mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "    if pc_full_path is not None:\n",
    "        o3d.io.write_point_cloud(pc_full_path, point_cloud)\n",
    "\n",
    "    return point_cloud\n",
    "# def point_cloud_generation_from_mesh(mesh_path, pc_full_path=None, timeout=30):\n",
    "#     def sample_points(mesh, pc_full_path=None):\n",
    "#         # Sample points on the mesh surface\n",
    "#         point_cloud = mesh.sample_points_poisson_disk(number_of_points=1000)\n",
    "\n",
    "#         # Save the point cloud if a path is provided\n",
    "#         if pc_full_path is not None:\n",
    "#             o3d.io.write_point_cloud(pc_full_path, point_cloud)\n",
    "\n",
    "#         return point_cloud\n",
    "        \n",
    "#     mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "#     # mesh = check_mesh_watertight_and_components(mesh)\n",
    "#     if mesh is None:\n",
    "#         return None\n",
    "\n",
    "#     # Use a thread pool to manage the timeout\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         future = executor.submit(sample_points, mesh, pc_full_path)\n",
    "#         try:\n",
    "#             # Wait for the result with a timeout\n",
    "#             point_cloud = future.result(timeout=timeout)\n",
    "#         except concurrent.futures.TimeoutError:\n",
    "#             print(f\"Timeout reached for {mesh_path}. Returning None.\")\n",
    "#             return None\n",
    "#     print(f\"Point cloud generated for {mesh_path}\")\n",
    "#     return point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException(\"Function call timed out\")\n",
    "\n",
    "\n",
    "def run_with_timeout(func, args=(), kwargs={}, timeout=10):\n",
    "    # Set the signal handler for SIGALRM\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    # Set the alarm for the specified timeout\n",
    "    signal.alarm(timeout)\n",
    "    try:\n",
    "        # Call the function with the provided arguments\n",
    "        result = func(*args, **kwargs)\n",
    "    except TimeoutException as e:\n",
    "        # Handle the timeout exception\n",
    "        print(e)\n",
    "        result = None\n",
    "    finally:\n",
    "        # Disable the alarm\n",
    "        signal.alarm(0)\n",
    "    return result\n",
    "\n",
    "def generate_point_clouds_from_class(class_name, loaded_objects):\n",
    "    base_dir = class_name + \"_point_clouds\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    # go through all plane_objects and generate point clouds\n",
    "    skipped = 0\n",
    "    for uid, mesh_path in tqdm(loaded_objects.items()):\n",
    "        pc_full_path = os.path.join(base_dir, f\"{uid}.ply\")\n",
    "        if os.path.exists(pc_full_path):\n",
    "            continue\n",
    "        \n",
    "        # returned_pc = point_cloud_generation_from_mesh(mesh_path, pc_full_path)\n",
    "        returned_pc = run_with_timeout(point_cloud_generation_from_mesh, args=(mesh_path, pc_full_path), timeout=30)\n",
    "\n",
    "        if returned_pc is None:\n",
    "            skipped += 1\n",
    "\n",
    "    print(f\"Skipped {skipped} objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"bicycle\"  # \"plane\", \"bicycle\", \"car\"\n",
    "loaded_objects = pd.read_csv(\n",
    "        class_name + \"_objects.csv\", index_col=0).to_dict()[\"0\"]\n",
    "print(f\"Generating point clouds for {len(loaded_objects)} {class_name} objects.\")\n",
    "generate_point_clouds_from_class(class_name, loaded_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"bicycle\"  # \"plane\", \"bicycle\", \"car\"\n",
    "generate_point_clouds_from_class(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"car\"  # \"plane\", \"bicycle\", \"car\"\n",
    "generate_point_clouds_from_class(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = class_name + \"_point_clouds\"\n",
    "# get all the point cloud files in the folder\n",
    "pc_files = [f for f in os.listdir(base_dir) if f.endswith(\".ply\")]\n",
    "\n",
    "for pc_file in pc_files:\n",
    "    full_path = os.path.join(base_dir, pc_file)\n",
    "    imgs = ply2projections(full_path)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for i, img in enumerate(imgs):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some further tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for single mesh to point cloud\n",
    "plane_uids = list(loaded_objects.keys())\n",
    "selected_element = loaded_objects[plane_uids[5]]\n",
    "\n",
    "pc_from_obj = point_cloud_generation_from_mesh(selected_element, pc_full_path=\"./tmp/pc_from_obj.ply\")\n",
    "if pc_from_obj is None:\n",
    "    print(\"Point cloud is None.\")\n",
    "else:\n",
    "    full_path = \"./tmp/pc_from_obj.ply\"\n",
    "    imgs = ply2projections(full_path)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for i, img in enumerate(imgs):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for single mesh to point cloud\n",
    "plane_uids = list(loaded_objects.keys())\n",
    "selected_element = loaded_objects[plane_uids[3]]\n",
    "\n",
    "pc_from_obj = point_cloud_generation_from_mesh(\n",
    "    selected_element, pc_full_path=\"./tmp/pc_from_obj.ply\")\n",
    "\n",
    "full_path = \"./tmp/pc_from_obj.ply\"\n",
    "imgs = ply2projections(full_path)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for i, img in enumerate(imgs):\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
